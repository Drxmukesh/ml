{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hugging Face","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Install Required Libraries\nInstall the Hugging Face libraries:","metadata":{}},{"cell_type":"code","source":"pip install transformers datasets torch\npip install huggingface_hub\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Format your data as text pairs:**\nHugging Face provides numerous lightweight models that you can fine-tune. For summarization or analysis, you might use:\n\n**Format your data as text pairs:**\nBART (Sequence-to-Sequence)\nDistilBERT (Compact version of BERT)\nExample: Choosing a summarization model like T5-small for compactness.\n\n**Format your data as text pairs:**\nIf you have a custom dataset:\n\n**Format your data as text pairs:**\nInput: Large text (to summarize or analyze)\nOutput: Summary or analysis results.\nSave the dataset in .csv or .json.\nExample format:","metadata":{}},{"cell_type":"code","source":"# csv\ninput_text,summary_text\n\"This is a long article about AI...\", \"AI revolutionizes industries.\"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Alternatively, use a public dataset like CNN/DailyMail:\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 4: Fine-tune the Model**\nUse the Trainer API for fine-tuning","metadata":{}},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\nfrom datasets import load_dataset\n\n# Load the tokenizer and model\nmodel_name = \"t5-small\"\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\n\n# Load dataset\ndataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:1%]\")  # Use a small portion for testing\n\n# Tokenize data\ndef preprocess_function(examples):\n    inputs = [\"summarize: \" + doc for doc in examples[\"article\"]]\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n\n    # Setup the tokenizer for targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(examples[\"highlights\"], max_length=150, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_dataset = dataset.map(preprocess_function, batched=True)\n\n# Set training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    num_train_epochs=1,\n    weight_decay=0.01,\n    save_total_limit=2,\n)\n\n# Define the trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n)\n\n# Train the model\ntrainer.train()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 5: Save the Fine-tuned Model\nSave the model for later use:","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"./my-mini-model\")\ntokenizer.save_pretrained(\"./my-mini-model\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 6: Test the Mini Model\r\nGenerate a summary or perform analysis using your fine-tuned mode","metadata":{}},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\n\n# Load the saved model\nmodel = T5ForConditionalGeneration.from_pretrained(\"./my-mini-model\")\ntokenizer = T5Tokenizer.from_pretrained(\"./my-mini-model\")\n\n# Input text\ntext = \"This is a long article about the importance of AI in modern industries.\"\n\n# Generate a summary\ninput_ids = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\noutputs = model.generate(input_ids, max_length=150, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\nprint(tokenizer.decode(outputs[0]))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 7: Share on Hugging Face\nCreate an account on Hugging Face.\nUse the huggingface_hub library to push your model","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token=\"your_hugging_face_token\")\n\nmodel.push_to_hub(\"my-mini-model\")\ntokenizer.push_to_hub(\"my-mini-model\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Now your model is hosted and ready to use**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}